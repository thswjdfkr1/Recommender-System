{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["6cZSBP00xyzF","jN9jFbfsx222","gukT4euDyNbi","hr5fJm2FyrpQ","k7xNJqmly7jk","-z5U6mKizGHN","dWZA6LudzUuk","r6-aZtoXzbCq","Z7H7fmFIznW1"],"authorship_tag":"ABX9TyOl9okLpqktcSCmvqPrkiC/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# SVD (Singular Value Decomposition) - í–‰ë ¬ ë¶„í•´ ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸"],"metadata":{"id":"6cZSBP00xyzF"}},{"cell_type":"code","source":["from surprise import SVD\n","from surprise import Dataset\n","from surprise.model_selection import cross_validate\n","\n","# ë‚´ì¥ ë°ì´í„°ì…‹ (MovieLens 100K)\n","data = Dataset.load_builtin('ml-100k')\n","\n","# SVD ëª¨ë¸ ìƒì„±\n","model = SVD()\n","\n","# êµì°¨ ê²€ì¦ì„ í†µí•œ ì„±ëŠ¥ í‰ê°€\n","cross_validate(model, data, cv=5, verbose=True)"],"metadata":{"id":"GdEOnY_XxzQC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# NCF (Neural Collaborative Filtering)\n","\n","í–‰ë ¬ ë¶„í•´(Matrix Factorization, MF)ë¥¼ ë”¥ëŸ¬ë‹ ê¸°ë°˜ìœ¼ë¡œ í™•ì¥í•œ ì¶”ì²œ ëª¨ë¸\n","\n","MFëŠ”\n","ğ‘…=\n","ğ‘ˆ\n","â‹…\n","ğ‘‰\n","ğ‘‡\n","R=Uâ‹…V\n","Tí˜•íƒœë¡œ ë¶„í•´í•˜ì§€ë§Œ,\n","NCFëŠ” ì´ë¥¼ ì‹ ê²½ë§ì„ í†µí•´ í•™ìŠµ\n","\n","ì‚¬ìš©ì & ì•„ì´í…œì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ í›„ ì‹ ê²½ë§ì„ í†µí•´ ì¶”ì²œì„ ìˆ˜í–‰\n","\n","\n","MFì™€ MLPë¥¼ í•©ì¹œ NeuMFê°€ ê°€ì¥ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì„\n"],"metadata":{"id":"jN9jFbfsx222"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n","\n","# ì‚¬ìš©ì & ì•„ì´í…œ ìˆ˜ ì •ì˜ (ì˜ˆì œ)\n","num_users = 1000\n","num_items = 1000\n","embedding_dim = 32  # ì„ë² ë”© ì°¨ì›\n","\n","# ì…ë ¥ ë ˆì´ì–´\n","user_input = Input(shape=(1,), name=\"user_input\")\n","item_input = Input(shape=(1,), name=\"item_input\")\n","\n","# ì„ë² ë”© ë ˆì´ì–´\n","user_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim)(user_input)\n","item_embedding = Embedding(input_dim=num_items, output_dim=embedding_dim)(item_input)\n","\n","# Flatten (ì°¨ì› ì¶•ì†Œ)\n","user_vec = Flatten()(user_embedding)\n","item_vec = Flatten()(item_embedding)\n","\n","# MLP ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸\n","concat = Concatenate()([user_vec, item_vec])\n","dense1 = Dense(128, activation='relu')(concat)\n","dense2 = Dense(64, activation='relu')(dense1)\n","dense3 = Dense(32, activation='relu')(dense2)\n","output = Dense(1, activation='sigmoid')(dense3)  # í‰ì  ì˜ˆì¸¡\n","\n","# ëª¨ë¸ ì •ì˜\n","ncf_model = Model(inputs=[user_input, item_input], outputs=output)\n","ncf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# ëª¨ë¸ êµ¬ì¡° ì¶œë ¥\n","ncf_model.summary()\n"],"metadata":{"id":"monERPoIyBgO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AutoEncoder ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ\n","\n","AutoEncoderë¥¼ ì‚¬ìš©í•´ ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ì„ ì••ì¶•(ì°¨ì› ì¶•ì†Œ)í•˜ì—¬ ì¶”ì²œ\n","\n","ê¸°ì¡´ MF ëª¨ë¸ë³´ë‹¤ ë¹„ì„ í˜•ì ì¸ íŠ¹ì§•ê¹Œì§€ í•™ìŠµ ê°€ëŠ¥\n","\n","í¬ì†Œ í–‰ë ¬ì„ ì••ì¶•í•˜ì—¬ íŠ¹ì§•ì„ ì¶”ì¶œ\n","\n","ê¸°ì¡´ MFë³´ë‹¤ ë¹„ì„ í˜•ì ì¸ íŒ¨í„´ì„ í•™ìŠµ ê°€ëŠ¥"],"metadata":{"id":"gukT4euDyNbi"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# AutoEncoder ëª¨ë¸ ì •ì˜\n","class AutoEncoder(nn.Module):\n","    def __init__(self, num_items, hidden_dim=64):\n","        super(AutoEncoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(num_items, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, 32),\n","            nn.ReLU()\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(32, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, num_items),\n","            nn.Sigmoid()  # ë³µì›ëœ ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬\n","        )\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded\n","\n","# ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ í¬ê¸° ì •ì˜\n","num_users, num_items = 1000, 1000\n","model = AutoEncoder(num_items)\n","\n","# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# ê°€ì§œ ì‚¬ìš©ì-ì•„ì´í…œ í–‰ë ¬ (ëœë¤ ë°ì´í„°)\n","input_data = torch.rand((num_users, num_items))\n","\n","# í•™ìŠµ\n","for epoch in range(10):\n","    optimizer.zero_grad()\n","    output = model(input_data)\n","    loss = criterion(output, input_data)\n","    loss.backward()\n","    optimizer.step()\n","    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")\n"],"metadata":{"id":"7LMdUGwMyQQX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Graph-based ì¶”ì²œ ì‹œìŠ¤í…œ (GNN ê¸°ë°˜ ì¶”ì²œ)\n","\n","ì¶”ì²œ ì‹œìŠ¤í…œì„ ê·¸ë˜í”„(Graph) í˜•íƒœë¡œ ëª¨ë¸ë§í•˜ì—¬ ì¶”ì²œì„ ìˆ˜í–‰\n","\n","ì‚¬ìš©ì-ì•„ì´í…œ ê´€ê³„ë¥¼ ì´ì›ƒ(Neighbor)ìœ¼ë¡œ ê°„ì£¼\n","\n","ì‚¬ìš©ì-ì•„ì´í…œ ê´€ê³„ë¥¼ ê·¸ë˜í”„ë¡œ ëª¨ë¸ë§í•˜ì—¬ ì¶”ì²œì„ ìˆ˜í–‰\n","\n","í˜‘ì—… í•„í„°ë§ë³´ë‹¤ ë” ë³µì¡í•œ ê´€ê³„(ì´ì›ƒ ì‚¬ìš©ì, ì•„ì´í…œ ê°„ ìœ ì‚¬ì„± ë“±)ë¥¼ í•™ìŠµ ê°€ëŠ¥"],"metadata":{"id":"hr5fJm2FyrpQ"}},{"cell_type":"code","source":["import dgl\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import dgl.function as fn\n","\n","# ê·¸ë˜í”„ ì‹ ê²½ë§ ëª¨ë¸ (GNN)\n","class GCN(nn.Module):\n","    def __init__(self, in_feats, hidden_feats, out_feats):\n","        super(GCN, self).__init__()\n","        self.layer1 = nn.Linear(in_feats, hidden_feats)\n","        self.layer2 = nn.Linear(hidden_feats, out_feats)\n","\n","    def forward(self, graph, features):\n","        h = torch.relu(self.layer1(features))\n","        graph.ndata['h'] = h\n","        graph.update_all(fn.copy_u('h', 'm'), fn.mean('m', 'h'))\n","        h = graph.ndata.pop('h')\n","        h = self.layer2(h)\n","        return h\n","\n","# ì‚¬ìš©ì-ì•„ì´í…œ ê·¸ë˜í”„ ìƒì„± (ì„ì˜ ë°ì´í„°)\n","num_users, num_items = 100, 100\n","edges_src = torch.randint(0, num_users, (500,))\n","edges_dst = torch.randint(0, num_items, (500,)) + num_users\n","\n","graph = dgl.graph((edges_src, edges_dst))\n","features = torch.rand((num_users + num_items, 32))\n","\n","# ëª¨ë¸ ì •ì˜\n","model = GCN(32, 64, 32)\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","loss_fn = nn.MSELoss()\n","\n","# í•™ìŠµ ê³¼ì •\n","for epoch in range(10):\n","    optimizer.zero_grad()\n","    output = model(graph, features)\n","    loss = loss_fn(output, features)\n","    loss.backward()\n","    optimizer.step()\n","    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}\")\n"],"metadata":{"id":"um-JPgepyy7O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ì‹œí€€ìŠ¤ ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ (Sequential Recommendation)\n","\n","ì‚¬ìš©ìì˜ ê³¼ê±° í–‰ë™(í´ë¦­, ì‹œì²­, êµ¬ë§¤ ë“±)ì„ ì‹œê³„ì—´ ë°ì´í„°ë¡œ ë³´ê³ , ë‹¤ìŒ í–‰ë™ì„ ì˜ˆì¸¡í•˜ëŠ” ì¶”ì²œ\n","\n","ë‹¨ìˆœí•œ í˜‘ì—… í•„í„°ë§ë³´ë‹¤ ì—°ì†ì ì¸ ì‚¬ìš©ì íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆìŒ\n","\n","Spotify, YouTube ì¶”ì²œ: ì´ì „ì— ë“¤ì—ˆë˜ ë…¸ë˜/ì˜ìƒ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ê³¡ ì¶”ì²œ\n","\n","Netflix, Disney+ ì¶”ì²œ: ì‹œì²­ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ"],"metadata":{"id":"k7xNJqmly7jk"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# RNN ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸\n","class RNNRecSys(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(RNNRecSys, self).__init__()\n","        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        out, _ = self.rnn(x)\n","        out = self.fc(out[:, -1, :])  # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì¶œë ¥ ì‚¬ìš©\n","        return out\n","\n","# ì…ë ¥: ì‚¬ìš©ì í–‰ë™ ì‹œí€€ìŠ¤ (ì˜ˆ: ìµœê·¼ ë³¸ ì˜í™”ë“¤)\n","model = RNNRecSys(input_dim=32, hidden_dim=64, output_dim=10)\n"],"metadata":{"id":"HCeJHyvEzAmP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Seq2Seq ëª¨ë¸ì„ ì¶”ì²œ ì‹œìŠ¤í…œì— ì ìš©í•˜ëŠ” ê²½ìš°\n","\n","**\"ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ë‹¤ìŒ ì¶”ì²œ ì•„ì´í…œ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜\"**í•˜ëŠ” ë¬¸ì œì— ì ìš© ê°€ëŠ¥\n","\n","\"ì´ì „ì— ë³¸ ì˜í™” â†’ ë‹¤ìŒì— ë³¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì˜í™” ì‹œí€€ìŠ¤ ì¶”ì²œ\"\n","\n","\"ìœ ì €ì˜ í–‰ë™ íŒ¨í„´ì„ ì‹œí€€ìŠ¤ë¡œ ë³´ê³ , ë‹¤ìŒ í´ë¦­í•  ì•„ì´í…œì„ ì˜ˆì¸¡\""],"metadata":{"id":"-z5U6mKizGHN"}},{"cell_type":"code","source":["class Seq2SeqRecSys(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(Seq2SeqRecSys, self).__init__()\n","        self.encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n","        self.decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        _, (h, c) = self.encoder(x)\n","        out, _ = self.decoder(x, (h, c))\n","        return self.fc(out[:, -1, :])\n","\n","model = Seq2SeqRecSys(input_dim=32, hidden_dim=64, output_dim=10)\n"],"metadata":{"id":"MFDguusMzGoe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  Attention ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ (Attention Mechanism in RecSys)\n","\n","Attentionì€ ì‚¬ìš©ìì˜ ê´€ì‹¬ë„(Attention Score)ë¥¼ í•™ìŠµí•˜ì—¬ ë” ì ì ˆí•œ ì•„ì´í…œì„ ì¶”ì²œí•  ìˆ˜ ìˆë„ë¡ ë„ì›€\n","\n","TikTok, Instagram Reels ì¶”ì²œ: ìœ ì €ê°€ íŠ¹ì • ìŠ¤íƒ€ì¼ì˜ ì˜ìƒì— ë” ì˜¤ë˜ ë¨¸ë¬¼ë©´ í•´ë‹¹ ìŠ¤íƒ€ì¼ì— ë†’ì€ Attentionì„ ë¶€ì—¬\n","\n","E-commerce (ì•„ë§ˆì¡´, ì¿ íŒ¡): ì‚¬ìš©ìê°€ ì§‘ì¤‘í–ˆë˜ ìƒí’ˆì˜ ìœ ì‚¬í•œ ìƒí’ˆ ì¶”ì²œ"],"metadata":{"id":"dWZA6LudzUuk"}},{"cell_type":"code","source":["class AttentionLayer(nn.Module):\n","    def __init__(self, input_dim):\n","        super(AttentionLayer, self).__init__()\n","        self.attn = nn.Linear(input_dim, 1)\n","\n","    def forward(self, x):\n","        attn_weights = torch.softmax(self.attn(x), dim=1)\n","        return torch.sum(attn_weights * x, dim=1)\n","\n","# ì‚¬ìš©ìì˜ ê³¼ê±° í–‰ë™ ì‹œí€€ìŠ¤ë¥¼ Attentionì„ í†µí•´ ì¶”ì²œ\n","attention_layer = AttentionLayer(input_dim=32)\n"],"metadata":{"id":"BvPAiPSwzZ3H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Transformerê°€ ì¶”ì²œ ì‹œìŠ¤í…œì—ì„œ ì“°ì´ëŠ” ê²½ìš°\n","\n","BERT4Rec (Amazon ì¶”ì²œ ì‹œìŠ¤í…œ): BERT ëª¨ë¸ì„ í™œìš©í•´ ìˆœì„œë¥¼ ë¬´ì‘ìœ„ë¡œ ë°”ê¿”ë„ ì¶”ì²œì´ ê°€ëŠ¥í•˜ë„ë¡ í•™ìŠµ\n","\n","SASRec (Self-Attention ê¸°ë°˜ ì¶”ì²œ): LSTMë³´ë‹¤ ë” ê°•ë ¥í•œ ì¶”ì²œ ì„±ëŠ¥\n","\n","GPT ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ: ëŒ€í™”í˜• ì¶”ì²œ (ì˜ˆ: ChatGPT ê¸°ë°˜ ì¶”ì²œ)"],"metadata":{"id":"r6-aZtoXzbCq"}},{"cell_type":"code","source":["class SASRec(nn.Module):\n","    def __init__(self, num_items, embedding_dim):\n","        super(SASRec, self).__init__()\n","        self.embedding = nn.Embedding(num_items, embedding_dim)\n","        self.transformer = nn.TransformerEncoder(\n","            nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=2),\n","            num_layers=2\n","        )\n","        self.fc = nn.Linear(embedding_dim, num_items)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = self.transformer(x)\n","        return self.fc(x[:, -1, :])\n","\n","model = SASRec(num_items=1000, embedding_dim=32)\n"],"metadata":{"id":"WrQ3KA0Izdg-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì²œ\n","\n","í…ìŠ¤íŠ¸+ì´ë¯¸ì§€ë¥¼ ê²°í•©í•œ ì¶”ì²œ ëª¨ë¸ì´ ë§ì´ ì‚¬ìš©\n","\n","Pinterest, ë„¤ì´ë²„ ì‡¼í•‘ â†’ \"ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ì˜ íŒ¨ì…˜ ì•„ì´í…œ ì¶”ì²œ\"\n","\n","TikTok, YouTube â†’ \"ì˜ìƒ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë¹„ìŠ·í•œ ì˜ìƒ ì¶”ì²œ\""],"metadata":{"id":"Z7H7fmFIznW1"}},{"cell_type":"code","source":["import torch\n","from transformers import CLIPProcessor, CLIPModel\n","\n","model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n","processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","image = torch.rand((3, 224, 224))  # ì„ì˜ì˜ ì´ë¯¸ì§€ ë°ì´í„°\n","text = [\"Nike ì‹ ë°œ\", \"Adidas ì‹ ë°œ\", \"Puma ì‹ ë°œ\"]\n","inputs = processor(images=image, text=text, return_tensors=\"pt\", padding=True)\n","\n","outputs = model(**inputs)\n","logits_per_image = outputs.logits_per_image\n","recommended_index = logits_per_image.argmax()\n","print(f\"ì¶”ì²œ ì•„ì´í…œ: {text[recommended_index]}\")\n"],"metadata":{"id":"zRV095p4zya1"},"execution_count":null,"outputs":[]}]}